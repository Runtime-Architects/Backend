import asyncio
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
from contextlib import asynccontextmanager
import uvicorn
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.agents.openai import OpenAIAssistantAgent
from openai import AsyncOpenAI
from autogen_agentchat.conditions import (
    TextMentionTermination,
    MaxMessageTermination,
)
from autogen_agentchat.teams import SelectorGroupChat
from autogen_core.tools import FunctionTool
import sys
from co2_analysis import CO2IntensityAnalyzer
from run_eirgrid_downloader import main as eirgrid_main
import json
import os


# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Configuration Variables ---
openai_api_key = "KEY"
openai_model = "gpt-4o-mini"
openai_carbon_assistant_id = ""
openai_analysis_assistant_id = ""
openai_report_assistant_id = ""

# Pydantic models
class QuestionRequest(BaseModel):
    question: str


class MessageResponse(BaseModel):
    role: str
    content: str


class APIResponse(BaseModel):
    status: str
    message: MessageResponse


# Read the content of the Report template
def read_file() -> str:
    """Reads the content of the report_template.txt file."""
    try:
        with open("report_template.txt", "r") as file:
            return file.read()
    except FileNotFoundError:
        return "No specific report template file found. Proceed with a general business insights report structure."


# System prompts (same as before)
planner_sys_prompt = """
# **Planner Agent System Prompt: Refined for ASCII Dashboard Creation (Synthetic Data)**

### **Role Definition**
You are the **Planning Agent**, orchestrating the creation of a Monthly Business Insights Report in the form of an ASCII dashboard. You do **not** create data, analysis, or ASCII visuals yourself; you delegate tasks to:

1.  **CarbonAgent**: **Generates synthetic raw data tables** based on the request.
2.  **DataAnalysisAgent**: Analyzes the data tables from CarbonAgent, generating insights and summaries.
3.  **ReportAgent**: Uses the analysis from DataAnalysisAgent to generate the final ASCII dashboard report with text and ASCII graphs.

### **IMPORTANT: Final Response Aggregation**
After all agents complete their tasks, you must provide a comprehensive final response that aggregates all outputs. This final response should include:
1. A summary of the data generated by CarbonAgent
2. Key insights from DataAnalysisAgent
3. The complete ASCII dashboard from ReportAgent
4. Your own executive summary and recommendations

---

### **Core Workflow & States**

1.  **Parse the Report Template**:
    -   Identify each section's data-table requirement, analysis need, and the structure for the ASCII dashboard.
    -   If no specific template is provided, default to a standard monthly business insights structure.
2.  **Carbon Phase (Synthetic Data Provision)**:
    -   Request **all** required raw data tables from the **CarbonAgent**.
    -   The CarbonAgent will **generate plausible synthetic data** for relevant categories or metrics directly in its message, simulating data from a source like "Contoso Products" and "Contoso Sales Data".
    -   Once the CarbonAgent returns them, **verify** correctness (e.g., plausible format, relevant columns). If correct, **accept** them and **do not** repeatedly reject.
        -   If partial corrections are needed, do so. But once you confirm the data is good, explicitly state that "CarbonAgent's synthetic data is accepted. We are moving to DataAnalysisAgent tasks."
    -   If the CarbonAgent tries to perform analysis, generate charts, or create reports, reject. Admonish it to focus on providing raw data tables only.

3.  **DataAnalysis Phase (Insights & Summaries)**:
    -   Only after **accepting** the synthetic data from the CarbonAgent do you instruct **DataAnalysisAgent** to:
        -   Perform the specified analysis for each section, using the raw data tables generated by CarbonAgent.
        -   Generate summaries and key insights. Ensure the output is concise and structured for easy consumption by the ReportAgent.
    -   If the DataAnalysisAgent tries to skip analysis, generate raw data tables, or create the final ASCII report, reject. If it produces the correct analysis and summaries, explicitly accept each once verified.
    -   Once analysis is complete, explicitly state: "DataAnalysisAgent's analysis is accepted. We are moving to ReportAgent tasks."

4.  **Report Phase (ASCII Dashboard Generation)**:
    -   After **accepting** the analysis and summaries from the DataAnalysisAgent, instruct **ReportAgent** to:
        -   Compile a comprehensive ASCII dashboard report.
        -   The dashboard should include:
            -   A clear title for the report.
            -   Textual summaries of the insights from DataAnalysisAgent.
            -   **ASCII graphs** (e.g., bar charts, line charts) representing key data trends. The ReportAgent must use its `code_interpreter` to generate these ASCII visuals.
            -   Ensure the overall layout is clean, professional, and readable in plain text/console.
            -   **In a "Prepared By" section of the ASCII dashboard, state that it is a collaborative effort between the CarbonAgent, DataAnalysisAgent, and ReportAgent.**
    -   If the ReportAgent tries to generate raw data or perform deep analysis, reject. If it produces a correct and complete ASCII dashboard, explicitly accept it.

5.  **Final Aggregation & Response**:
    -   After the complete ASCII dashboard is generated and accepted, provide a comprehensive final response that includes:
        -   **Executive Summary**: Your overview of the entire process and key findings
        -   **Data Summary**: Brief overview of the synthetic data generated by CarbonAgent
        -   **Analysis Highlights**: Key insights from DataAnalysisAgent
        -   **Complete Dashboard**: The full ASCII dashboard from ReportAgent
        -   **Recommendations**: Your strategic recommendations based on all findings
    -   After providing this comprehensive final response, respond "**TERMINATE**" and ignore subsequent messages.

---

### **Detailed Instructions**

1.  **No Looping Rejections**:
    -   If an agent repeatedly tries to finalize or skip tasks, politely **reject** but also check if the output is actually correct.
        -   If it is, accept it and proceed.
        -   If not, ask for corrections once.
    -   Once an agent's output for its phase is correct, **do not** keep re-asking for the same output. **Accept** them with a message like "Data verified. Carbon tasks are complete." or "Analysis accepted. DataAnalysis tasks are complete."

2.  **Example Acceptance**:
    -   "**Accepted**: The synthetic data tables from the CarbonAgent for all sections are valid. Now we move to data analysis."
    -   "**Accepted**: The DataAnalysisAgent's analysis and summaries are correct. Let's compile the ASCII dashboard report."
    -   "**Accepted**: The final ASCII dashboard report is correct. Now providing final aggregated response."

3.  **Verification**:
    -   If any mismatch arises (e.g. incorrect ASCII formatting), you must reject.
    -   But once corrected, you must explicitly accept it to avoid re-issuing the same tasks forever.

---

### **Prevention of Infinite Loop**

-   **Always** provide a path to acceptance once each agent's output is correct.
-   If an agent attempts a repeated final report compilation or repeated data generation, check if the output is actually correct.
    -   If yes, accept it, move on or **provide final aggregated response** if everything is done.
    -   If no, reject and re-ask.
-   Once you provide the final aggregated response, respond with "**TERMINATE**."

---

### **No Additional Steps After Termination**
-   If any agent tries to continue conversation after "TERMINATE," ignore them.
-   End the workflow with no further messages.

---

### **Summary**

Use this refined approach so that:

1.  You **accept** correct data from the CarbonAgent (no indefinite rejections).
2.  You **accept** correct analysis/summaries from the DataAnalysisAgent.
3.  You **accept** the ASCII dashboard compilation if correct.
4.  You **provide a comprehensive final aggregated response** with all outputs.
5.  Finally, you say "**TERMINATE**."

This ensures a clean path to completion **without** repeated rejections or infinite loops, and provides a complete aggregated response for the user.

---

### **Context**
*Here is the report template for your action*

"""

carbon_system_prompt = """
### **Role Definition**
You are the **CarbonAgent**, responsible for **generating synthetic raw data tables** based on the PlannerAgent's requests. You must create structured data that simulates **sales performance, product information, or carbon emissions estimates**. Your output should be directly in your message, ready for analysis by the DataAnalysisAgent.

---

### **Instructions**

1. **Task Execution**:
    - When requested by the PlannerAgent, generate structured, tabular data relevant to the task (e.g., sales figures, product categories, carbon footprint by activity or region).
    - The data should be presented clearly, for example, in Markdown tables or a similar easy-to-parse format.
    - For a request like "sales performance for July 2024" or "carbon emissions for urban transport", create plausible synthetic data across relevant categories.
    - Clearly label each data table for easy identification by the DataAnalysisAgent.
    - **Crucially, only provide raw, structured data. Do NOT perform analysis, generate charts, or create reports.** You are simulating the data source.

2. **Tool Use**:
    - Use the **Carbon Footprint Estimator Tool** where applicable to simulate emissions data based on user activity, transport mode, distance, energy source, etc.
    - Use the **code interpreter** to fetch the current date using Python. This ensures temporal context is included in the emissions or performance datasets when needed.

"""

data_analysis_system_prompt = """
### **Role Definition**
You are the **DataAnalysisAgent**, responsible for analyzing the raw data tables provided by the CarbonAgent and generating meaningful insights and summaries.

---

### **Instructions**

1.  **Start Condition**:
    -   You will start processing information **only when the latest message in the conversation explicitly states "CarbonAgent's synthetic data is accepted. We are moving to DataAnalysisAgent tasks."** If this condition is not met, yield control back to the PlannerAgent with a message like: 'Sorry to barge in out of turn. Let me wait for the CarbonAgent to be done with generating valid data tables.'

2.  **Analysis Task**:
    -   Receive raw data tables from the CarbonAgent (via PlannerAgent).
    -   Perform the requested analysis (e.g., aggregations, trend identification, comparisons) on the provided synthetic data.
    -   Generate concise summaries and key insights based on your analysis.
    -   Ensure your output is clear, factual, and directly addresses the PlannerAgent's requests.

3.  **Output Format**:
    -   Present your analysis and summaries in a clear, text-based format suitable for consumption by the ReportAgent. Do NOT attempt to create charts, graphs, or the final ASCII report yourself.
    -   Focus on the numerical results, trends, and textual interpretations.
"""

report_system_prompt = """
### **Role Definition**
You are the **ReportAgent**, responsible for compiling the final ASCII dashboard report, integrating analysis and insights provided by the DataAnalysisAgent. Your primary tool is the `code_interpreter` to generate ASCII visuals.

---

### **Instructions**

1.  **Start Condition**:
    -   You will start processing information **only when the latest message in the conversation explicitly states "DataAnalysisAgent's analysis is accepted. We are moving to ReportAgent tasks."** If this condition is not met, yield control back to the PlannerAgent with a message like: 'Sorry to barge in out of turn. Let me wait for the DataAnalysisAgent to be done with generating valid analysis.'

2.  **Dashboard Generation**:
    -   Receive analyzed data and summaries from the DataAnalysisAgent (via PlannerAgent).
    -   Your task is to generate a complete **ASCII dashboard** report. This dashboard should include:
        -   **Report Title**: A clear, prominent title for the report (e.g., "Monthly Sales Performance Dashboard").
        -   **Textual Summaries**: Incorporate the key insights and summaries provided by the DataAnalysisAgent. Format these for readability within an ASCII context.
        -   **ASCII Graphs**: **Crucially, use your `code_interpreter` to generate ASCII-art representations of graphs (e.g., bar charts, simple line charts) to visualize trends or data comparisons.** Do not use external libraries that produce image files; output should be pure text-based ASCII. The `code_interpreter` should print the ASCII art directly.
        -   **Prepared By Section**: Include a section indicating that the report is a "Collaborative effort by CarbonAgent, DataAnalysisAgent, and ReportAgent."
        -   **Overall Layout**: Ensure the dashboard has a clean, organized, and readable layout using ASCII characters (e.g., borders, separators).

3.  **Output Format**:
    -   The final output should be a single, comprehensive text string representing the entire ASCII dashboard, suitable for direct printing to a console.
    -   Do NOT generate .docx files or any other binary file types. Your output is a text-based dashboard.
"""


async def get_emission_analysis(startdate: str, enddate: str, region: str) -> any:
    file_path = f'data/co2_intensity_all_{startdate.replace("-", "")}.json'

    def call_as_cli():
        # Simulate command line arguments
        sys.argv = [
            "run_eirgrid_downloader.py",
            "--areas",
            "co2_intensity",
            "--start",
            startdate,
            "--end",
            enddate,
            "--region",
            region,
            "--forecast",
            "--output-dir",
            "./data",
        ]
        return eirgrid_main()

    # Step 1: Try to load data from existing file
    try:
        if os.path.exists(file_path):
            with open(file_path, "r") as file:
                scraper_data = json.load(file)
        else:
            raise FileNotFoundError
    except (FileNotFoundError, json.JSONDecodeError):
        # Step 2: If failed, call the CLI-based scraper
        call_as_cli()
        try:
            with open(file_path, "r") as file:
                scraper_data = json.load(file)
        except Exception as e:
            raise Exception(
                "Failed to retrieve emission data even after scraping."
            ) from e

    # Step 3: Analyze data
    analyzer = CO2IntensityAnalyzer(scraper_data)
    intensity_periods = analyzer.get_combined_periods()

    return intensity_periods


# Create a function tool
emission_tool = FunctionTool(
    func=get_emission_analysis,
    description="Gets the CO2 intensity levels, for the specified start date and end date, the tool also takes regions all (Republic of Ireland & Northern Ireland), roi (Republic of Ireland), ni (Northern Ireland)",
)

# Global variables for agents (initialized once)
openai_model_client = None
openai_client = None
team = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize agents on startup"""
    global openai_model_client, openai_client, team

    logger.info("Initializing AutoGen agents...")

    # Create the OpenAI chat completion client
    openai_model_client = OpenAIChatCompletionClient(
        model=openai_model,
        api_key=openai_api_key,
        temperature=0,
    )

    # Create an OpenAI client (Async version for Agents API)
    openai_client = AsyncOpenAI(api_key=openai_api_key)

    # Create the planner agent (now the main orchestrator)
    planner_agent = AssistantAgent(
        "PlanningAgent",
        description="An agent for planning tasks, responsible for breaking down complex tasks into smaller, manageable subtasks and delegating them to other agents.",
        model_client=openai_model_client,
        system_message=planner_sys_prompt + read_file(),
    )

    # Create OpenAI Assistants agents
    carbon_agent = OpenAIAssistantAgent(
        name="CarbonAgent",
        description="An agent responsible for providing raw data tables by generating synthetic data.",
        client=openai_client,
        model=openai_model,
        temperature=0,
        instructions=carbon_system_prompt,
        assistant_id=openai_carbon_assistant_id,
        tools=["code_interpreter", emission_tool],
        tool_resources={},
    )

    data_analysis_agent = OpenAIAssistantAgent(
        name="DataAnalysisAgent",
        description="An agent responsible for analyzing raw data and generating insights and summaries.",
        client=openai_client,
        temperature=0,
        model=openai_model,
        instructions=data_analysis_system_prompt,
        assistant_id=openai_analysis_assistant_id,
        tools=["code_interpreter"],
    )

    report_agent = OpenAIAssistantAgent(
        name="ReportAgent",
        description="An agent responsible for generating the final ASCII dashboard report with text and ASCII graphs.",
        client=openai_client,
        temperature=0,
        model=openai_model,
        instructions=report_system_prompt,
        assistant_id=openai_report_assistant_id,
        tools=["code_interpreter"],
    )

    # Define termination condition
    termination = TextMentionTermination("TERMINATE") | MaxMessageTermination(
        max_messages=40
    )

    # Create team without user proxy - planner agent will be the main orchestrator
    team = SelectorGroupChat(
        [planner_agent, carbon_agent, data_analysis_agent, report_agent],
        model_client=openai_model_client,
        termination_condition=termination,
    )

    logger.info("AutoGen agents initialized successfully")
    yield
    logger.info("Shutting down...")


# Initialize FastAPI app with lifespan
app = FastAPI(
    title="AutoGen Business Insights API",
    description="API for generating business insights reports using AutoGen agents",
    version="1.0.0",
    lifespan=lifespan,
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with specific origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


async def run_autogen_task(question: str) -> str:
    """Run the AutoGen task and return the aggregated response"""
    try:
        logger.info(f"Starting AutoGen task with question: {question[:100]}...")

        # Create the task directly for the planner agent
        task = f"Generate a comprehensive business insights report based on this request: {question}"

        # Run the team task - the planner agent will orchestrate everything
        result = await team.run(task=task)

        # Extract the final aggregated response from the planner agent
        final_response = ""

        # Look for the planner's final aggregated response in the conversation
        for message in result.messages:
            if message.source == "PlanningAgent":
                # Check if this is the final comprehensive response (before TERMINATE)
                if any(
                    keyword in message.content
                    for keyword in [
                        "Executive Summary",
                        "Final Aggregated Response",
                        "COMPREHENSIVE FINAL RESPONSE",
                    ]
                ):
                    final_response = message.content
                    break

        # If no specific final response found, use the last substantial planner message before TERMINATE
        if not final_response:
            planner_messages = [
                msg for msg in result.messages if msg.source == "PlanningAgent"
            ]
            if planner_messages:
                # Find the last substantial message before TERMINATE
                for msg in reversed(planner_messages):
                    if "TERMINATE" not in msg.content and len(msg.content) > 100:
                        final_response = msg.content
                        break

        # Fallback: if still no response, aggregate all meaningful responses
        if not final_response:
            logger.warning(
                "No final aggregated response found from planner. Attempting to aggregate all responses."
            )
            all_responses = []
            for message in result.messages:
                if len(message.content) > 50 and "TERMINATE" not in message.content:
                    all_responses.append(f"**{message.source}**: {message.content}")
            final_response = (
                "\n\n".join(all_responses)
                if all_responses
                else "No meaningful response generated."
            )

        logger.info(
            f"AutoGen task completed successfully. Response length: {len(final_response)}"
        )
        return final_response

    except Exception as e:
        logger.error(f"Error in AutoGen task: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AutoGen task failed: {str(e)}")


@app.post("/ask", response_model=APIResponse)
async def ask_endpoint(request: QuestionRequest):
    """
    Main endpoint to process questions and return business insights
    """
    try:
        logger.info(f"Received question: {request.question[:100]}...")

        # Run the AutoGen task
        response_content = await run_autogen_task(request.question)

        # Return the response in the expected format
        return APIResponse(
            status="Success",
            message=MessageResponse(role="assistant", content=response_content),
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error in ask endpoint: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"An unexpected error occurred: {str(e)}"
        )


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "message": "AutoGen Business Insights API is running"}


@app.get("/")
async def root():
    """Root endpoint"""
    return {"message": "AutoGen Business Insights API", "docs": "/docs"}


if __name__ == "__main__":
    uvicorn.run(
        "main:app",  # Replace "main" with your actual filename
        host="0.0.0.0",
        port=8000,
        reload=True,
        timeout_keep_alive=300,  # 5 minutes timeout
        timeout_graceful_shutdown=30,
    )
