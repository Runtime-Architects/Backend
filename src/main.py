import asyncio
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import logging
from contextlib import asynccontextmanager
import uvicorn
import queue
import threading
import time
from datetime import datetime
from typing import AsyncGenerator, Dict, Any
from enum import Enum
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.agents.openai import OpenAIAssistantAgent
from openai import AsyncOpenAI
from autogen_agentchat.conditions import (
    TextMentionTermination,
    MaxMessageTermination,
)
from autogen_agentchat.teams import SelectorGroupChat
from autogen_core.tools import FunctionTool
import sys
from co2_analysis import CO2IntensityAnalyzer
from run_eirgrid_downloader import main as eirgrid_main
import json
import os


# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create a separate logger for streaming events
stream_logger = logging.getLogger("stream_events")
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(logging.Formatter('%(asctime)s - STREAM - %(levelname)s - %(message)s'))
stream_logger.addHandler(stream_handler)
stream_logger.setLevel(logging.INFO)

# --- Configuration Variables ---
openai_api_key = "key"
openai_model = "gpt-4o-mini"
openai_carbon_assistant_id = ""
openai_analysis_assistant_id = ""
openai_report_assistant_id = ""

# Pydantic models
class QuestionRequest(BaseModel):
    question: str


class MessageResponse(BaseModel):
    role: str
    content: str


class APIResponse(BaseModel):
    status: str
    message: MessageResponse


class StreamEventType(str, Enum):
    STARTED = "started"
    AGENT_THINKING = "agent_thinking"
    AGENT_RESPONSE = "agent_response"
    TOOL_EXECUTION = "tool_execution"
    ERROR = "error"
    COMPLETED = "completed"


class StreamEvent(BaseModel):
    event_type: StreamEventType
    timestamp: str
    agent_name: str = ""
    message: str = ""
    data: Dict[str, Any] = {}


class StreamResponse(BaseModel):
    event: StreamEvent
    message: MessageResponse


# Read the content of the Report template
def read_file() -> str:
    """Reads the content of the report_template.txt file."""
    try:
        with open("report_template.txt", "r") as file:
            return file.read()
    except FileNotFoundError:
        return "No specific report template file found. Proceed with a general business insights report structure."


# System prompts (same as before)
planner_sys_prompt = """
# **Planner Agent System Prompt: Refined for ASCII Dashboard Creation (Synthetic Data)**

### **Role Definition**
You are the **Planning Agent**, orchestrating the creation of a Monthly Business Insights Report in the form of an ASCII dashboard. You do **not** create data, analysis, or ASCII visuals yourself; you delegate tasks to:

1.  **CarbonAgent**: **Generates synthetic raw data tables** based on the request.
2.  **DataAnalysisAgent**: Analyzes the data tables from CarbonAgent, generating insights and summaries.
3.  **ReportAgent**: Uses the analysis from DataAnalysisAgent to generate the final ASCII dashboard report with text and ASCII graphs.

### **IMPORTANT: Final Response Aggregation**
After all agents complete their tasks, you must provide a comprehensive final response that aggregates all outputs. This final response should include:
1. A summary of the data generated by CarbonAgent
2. Key insights from DataAnalysisAgent
3. The complete ASCII dashboard from ReportAgent
4. Your own executive summary and recommendations

---

### **Core Workflow & States**

1.  **Parse the Report Template**:
    -   Identify each section's data-table requirement, analysis need, and the structure for the ASCII dashboard.
    -   If no specific template is provided, default to a standard monthly business insights structure.
2.  **Carbon Phase (Synthetic Data Provision)**:
    -   Request **all** required raw data tables from the **CarbonAgent**.
    -   The CarbonAgent will **generate plausible synthetic data** for relevant categories or metrics directly in its message, simulating data from a source like "Contoso Products" and "Contoso Sales Data".
    -   Once the CarbonAgent returns them, **verify** correctness (e.g., plausible format, relevant columns). If correct, **accept** them and **do not** repeatedly reject.
        -   If partial corrections are needed, do so. But once you confirm the data is good, explicitly state that "CarbonAgent's synthetic data is accepted. We are moving to DataAnalysisAgent tasks."
    -   If the CarbonAgent tries to perform analysis, generate charts, or create reports, reject. Admonish it to focus on providing raw data tables only.

3.  **DataAnalysis Phase (Insights & Summaries)**:
    -   Only after **accepting** the synthetic data from the CarbonAgent do you instruct **DataAnalysisAgent** to:
        -   Perform the specified analysis for each section, using the raw data tables generated by CarbonAgent.
        -   Generate summaries and key insights. Ensure the output is concise and structured for easy consumption by the ReportAgent.
    -   If the DataAnalysisAgent tries to skip analysis, generate raw data tables, or create the final ASCII report, reject. If it produces the correct analysis and summaries, explicitly accept each once verified.
    -   Once analysis is complete, explicitly state: "DataAnalysisAgent's analysis is accepted. We are moving to ReportAgent tasks."

4.  **Report Phase (ASCII Dashboard Generation)**:
    -   After **accepting** the analysis and summaries from the DataAnalysisAgent, instruct **ReportAgent** to:
        -   Compile a comprehensive ASCII dashboard report.
        -   The dashboard should include:
            -   A clear title for the report.
            -   Textual summaries of the insights from DataAnalysisAgent.
            -   **ASCII graphs** (e.g., bar charts, line charts) representing key data trends. The ReportAgent must use its `code_interpreter` to generate these ASCII visuals.
            -   Ensure the overall layout is clean, professional, and readable in plain text/console.
            -   **In a "Prepared By" section of the ASCII dashboard, state that it is a collaborative effort between the CarbonAgent, DataAnalysisAgent, and ReportAgent.**
    -   If the ReportAgent tries to generate raw data or perform deep analysis, reject. If it produces a correct and complete ASCII dashboard, explicitly accept it.

5.  **Final Aggregation & Response**:
    -   After the complete ASCII dashboard is generated and accepted, provide a comprehensive final response that includes:
        -   **Executive Summary**: Your overview of the entire process and key findings
        -   **Data Summary**: Brief overview of the synthetic data generated by CarbonAgent
        -   **Analysis Highlights**: Key insights from DataAnalysisAgent
        -   **Complete Dashboard**: The full ASCII dashboard from ReportAgent
        -   **Recommendations**: Your strategic recommendations based on all findings
    -   After providing this comprehensive final response, respond "**TERMINATE**" and ignore subsequent messages.

---

### **Detailed Instructions**

1.  **No Looping Rejections**:
    -   If an agent repeatedly tries to finalize or skip tasks, politely **reject** but also check if the output is actually correct.
        -   If it is, accept it and proceed.
        -   If not, ask for corrections once.
    -   Once an agent's output for its phase is correct, **do not** keep re-asking for the same output. **Accept** them with a message like "Data verified. Carbon tasks are complete." or "Analysis accepted. DataAnalysis tasks are complete."

2.  **Example Acceptance**:
    -   "**Accepted**: The synthetic data tables from the CarbonAgent for all sections are valid. Now we move to data analysis."
    -   "**Accepted**: The DataAnalysisAgent's analysis and summaries are correct. Let's compile the ASCII dashboard report."
    -   "**Accepted**: The final ASCII dashboard report is correct. Now providing final aggregated response."

3.  **Verification**:
    -   If any mismatch arises (e.g. incorrect ASCII formatting), you must reject.
    -   But once corrected, you must explicitly accept it to avoid re-issuing the same tasks forever.

---

### **Prevention of Infinite Loop**

-   **Always** provide a path to acceptance once each agent's output is correct.
-   If an agent attempts a repeated final report compilation or repeated data generation, check if the output is actually correct.
    -   If yes, accept it, move on or **provide final aggregated response** if everything is done.
    -   If no, reject and re-ask.
-   Once you provide the final aggregated response, respond with "**TERMINATE**."

---

### **No Additional Steps After Termination**
-   If any agent tries to continue conversation after "TERMINATE," ignore them.
-   End the workflow with no further messages.

---

### **Summary**

Use this refined approach so that:

1.  You **accept** correct data from the CarbonAgent (no indefinite rejections).
2.  You **accept** correct analysis/summaries from the DataAnalysisAgent.
3.  You **accept** the ASCII dashboard compilation if correct.
4.  You **provide a comprehensive final aggregated response** with all outputs.
5.  Finally, you say "**TERMINATE**."

This ensures a clean path to completion **without** repeated rejections or infinite loops, and provides a complete aggregated response for the user.

---

### **Context**
*Here is the report template for your action*

"""

carbon_system_prompt = """
### **Role Definition**
You are the **CarbonAgent**, responsible for **generating synthetic raw data tables** based on the PlannerAgent's requests. You must create structured data that simulates **sales performance, product information, or carbon emissions estimates**. Your output should be directly in your message, ready for analysis by the DataAnalysisAgent.

---

### **Instructions**

1. **Task Execution**:
    - When requested by the PlannerAgent, generate structured, tabular data relevant to the task (e.g., sales figures, product categories, carbon footprint by activity or region).
    - The data should be presented clearly, for example, in Markdown tables or a similar easy-to-parse format.
    - For a request like "sales performance for July 2024" or "carbon emissions for urban transport", create plausible synthetic data across relevant categories.
    - Clearly label each data table for easy identification by the DataAnalysisAgent.
    - **Crucially, only provide raw, structured data. Do NOT perform analysis, generate charts, or create reports.** You are simulating the data source.

2. **Tool Use**:
    - Use the **Carbon Footprint Estimator Tool** where applicable to simulate emissions data based on user activity, transport mode, distance, energy source, etc.
    - Use the **code interpreter** to fetch the current date using Python. This ensures temporal context is included in the emissions or performance datasets when needed.

"""

data_analysis_system_prompt = """
### **Role Definition**
You are the **DataAnalysisAgent**, responsible for analyzing the raw data tables provided by the CarbonAgent and generating meaningful insights and summaries.

---

### **Instructions**

1.  **Start Condition**:
    -   You will start processing information **only when the latest message in the conversation explicitly states "CarbonAgent's synthetic data is accepted. We are moving to DataAnalysisAgent tasks."** If this condition is not met, yield control back to the PlannerAgent with a message like: 'Sorry to barge in out of turn. Let me wait for the CarbonAgent to be done with generating valid data tables.'

2.  **Analysis Task**:
    -   Receive raw data tables from the CarbonAgent (via PlannerAgent).
    -   Perform the requested analysis (e.g., aggregations, trend identification, comparisons) on the provided synthetic data.
    -   Generate concise summaries and key insights based on your analysis.
    -   Ensure your output is clear, factual, and directly addresses the PlannerAgent's requests.

3.  **Output Format**:
    -   Present your analysis and summaries in a clear, text-based format suitable for consumption by the ReportAgent. Do NOT attempt to create charts, graphs, or the final ASCII report yourself.
    -   Focus on the numerical results, trends, and textual interpretations.
"""

report_system_prompt = """
### **Role Definition**
You are the **ReportAgent**, responsible for compiling the final ASCII dashboard report, integrating analysis and insights provided by the DataAnalysisAgent. Your primary tool is the `code_interpreter` to generate ASCII visuals.

---

### **Instructions**

1.  **Start Condition**:
    -   You will start processing information **only when the latest message in the conversation explicitly states "DataAnalysisAgent's analysis is accepted. We are moving to ReportAgent tasks."** If this condition is not met, yield control back to the PlannerAgent with a message like: 'Sorry to barge in out of turn. Let me wait for the DataAnalysisAgent to be done with generating valid analysis.'

2.  **Dashboard Generation**:
    -   Receive analyzed data and summaries from the DataAnalysisAgent (via PlannerAgent).
    -   Your task is to generate a complete **ASCII dashboard** report. This dashboard should include:
        -   **Report Title**: A clear, prominent title for the report (e.g., "Monthly Sales Performance Dashboard").
        -   **Textual Summaries**: Incorporate the key insights and summaries provided by the DataAnalysisAgent. Format these for readability within an ASCII context.
        -   **ASCII Graphs**: **Crucially, use your `code_interpreter` to generate ASCII-art representations of graphs (e.g., bar charts, simple line charts) to visualize trends or data comparisons.** Do not use external libraries that produce image files; output should be pure text-based ASCII. The `code_interpreter` should print the ASCII art directly.
        -   **Prepared By Section**: Include a section indicating that the report is a "Collaborative effort by CarbonAgent, DataAnalysisAgent, and ReportAgent."
        -   **Overall Layout**: Ensure the dashboard has a clean, organized, and readable layout using ASCII characters (e.g., borders, separators).

3.  **Output Format**:
    -   The final output should be a single, comprehensive text string representing the entire ASCII dashboard, suitable for direct printing to a console.
    -   Do NOT generate .docx files or any other binary file types. Your output is a text-based dashboard.
"""


async def get_emission_analysis(startdate: str, enddate: str, region: str) -> any:
    file_path = f'data/co2_intensity_all_{startdate.replace("-", "")}.json'

    def call_as_cli():
        # Simulate command line arguments
        sys.argv = [
            "run_eirgrid_downloader.py",
            "--areas",
            "co2_intensity",
            "--start",
            startdate,
            "--end",
            enddate,
            "--region",
            region,
            "--forecast",
            "--output-dir",
            "./data",
        ]
        return eirgrid_main()

    # Step 1: Try to load data from existing file
    try:
        if os.path.exists(file_path):
            with open(file_path, "r") as file:
                scraper_data = json.load(file)
        else:
            raise FileNotFoundError
    except (FileNotFoundError, json.JSONDecodeError):
        # Step 2: If failed, call the CLI-based scraper
        call_as_cli()
        try:
            with open(file_path, "r") as file:
                scraper_data = json.load(file)
        except Exception as e:
            raise Exception(
                "Failed to retrieve emission data even after scraping."
            ) from e

    # Step 3: Analyze data
    analyzer = CO2IntensityAnalyzer(scraper_data)
    intensity_periods = analyzer.get_combined_periods()

    return intensity_periods


# Create a function tool
emission_tool = FunctionTool(
    func=get_emission_analysis,
    description="Gets the CO2 intensity levels, for the specified start date and end date, the tool also takes regions all (Republic of Ireland & Northern Ireland), roi (Republic of Ireland), ni (Northern Ireland)",
)

# Global variables for agents (initialized once)
openai_model_client = None
openai_client = None
team = None


class StreamEventManager:
    """Manages streaming events and logging for AutoGen conversations"""
    
    def __init__(self):
        self.events = []
        self.current_step = 0
        self.total_steps = 4  # Adjust based on your workflow
        
    async def emit_event(self, event_type: StreamEventType, agent_name: str = "", 
                        message: str = "", data: Dict[str, Any] = None) -> StreamEvent:
        """Emit a streaming event and log it"""
        event = StreamEvent(
            event_type=event_type,
            timestamp=datetime.now().isoformat(),
            agent_name=agent_name,
            message=message,
            data=data or {}
        )
        
        self.events.append(event)
        
        # Log the event
        stream_logger.info(f"Event: {event_type} | Agent: {agent_name} | Message: {message}")
        
        return event
    
    def get_progress_percentage(self) -> int:
        """Calculate progress percentage"""
        return min(int((self.current_step / self.total_steps) * 100), 100)
    
    def increment_step(self):
        """Increment current step"""
        self.current_step += 1


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize agents on startup"""
    global openai_model_client, openai_client, team

    logger.info("Initializing AutoGen agents...")

    # Create the OpenAI chat completion client
    openai_model_client = OpenAIChatCompletionClient(
        model=openai_model,
        api_key=openai_api_key,
        temperature=0,
    )

    # Create an OpenAI client (Async version for Agents API)
    openai_client = AsyncOpenAI(api_key=openai_api_key)

    # Create the planner agent (now the main orchestrator)
    planner_agent = AssistantAgent(
        "PlanningAgent",
        description="An agent for planning tasks, responsible for breaking down complex tasks into smaller, manageable subtasks and delegating them to other agents.",
        model_client=openai_model_client,
        system_message=planner_sys_prompt + read_file(),
    )

    # Create OpenAI Assistants agents
    carbon_agent = OpenAIAssistantAgent(
        name="CarbonAgent",
        description="An agent responsible for providing raw data tables by generating synthetic data.",
        client=openai_client,
        model=openai_model,
        temperature=0,
        instructions=carbon_system_prompt,
        assistant_id=openai_carbon_assistant_id,
        tools=["code_interpreter", emission_tool],
        tool_resources={},
    )

    data_analysis_agent = OpenAIAssistantAgent(
        name="DataAnalysisAgent",
        description="An agent responsible for analyzing raw data and generating insights and summaries.",
        client=openai_client,
        temperature=0,
        model=openai_model,
        instructions=data_analysis_system_prompt,
        assistant_id=openai_analysis_assistant_id,
        tools=["code_interpreter"],
    )

    report_agent = OpenAIAssistantAgent(
        name="ReportAgent",
        description="An agent responsible for generating the final ASCII dashboard report with text and ASCII graphs.",
        client=openai_client,
        temperature=0,
        model=openai_model,
        instructions=report_system_prompt,
        assistant_id=openai_report_assistant_id,
        tools=["code_interpreter"],
    )

    # Define termination condition
    termination = TextMentionTermination("TERMINATE") | MaxMessageTermination(
        max_messages=40
    )

    # Create team without user proxy - planner agent will be the main orchestrator
    team = SelectorGroupChat(
        [planner_agent, carbon_agent, data_analysis_agent, report_agent],
        model_client=openai_model_client,
        termination_condition=termination,
    )

    logger.info("AutoGen agents initialized successfully")
    yield
    logger.info("Shutting down...")


# Initialize FastAPI app with lifespan
app = FastAPI(
    title="AutoGen Business Insights API",
    description="API for generating business insights reports using AutoGen agents",
    version="1.0.0",
    lifespan=lifespan,
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with specific origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


async def run_autogen_task(question: str) -> str:
    """Run the AutoGen task and return the aggregated response"""
    try:
        logger.info(f"Starting AutoGen task with question: {question[:100]}...")

        # Create the task directly for the planner agent
        task = f"Generate a comprehensive business insights report based on this request: {question}"

        # Run the team task - the planner agent will orchestrate everything
        result = await team.run(task=task)

        # Extract the final aggregated response from the planner agent
        final_response = ""

        # Look for the planner's final aggregated response in the conversation
        for message in result.messages:
            if message.source == "PlanningAgent":
                # Check if this is the final comprehensive response (before TERMINATE)
                if any(
                    keyword in message.content
                    for keyword in [
                        "Executive Summary",
                        "Final Aggregated Response",
                        "COMPREHENSIVE FINAL RESPONSE",
                    ]
                ):
                    final_response = message.content
                    break

        # If no specific final response found, use the last substantial planner message before TERMINATE
        if not final_response:
            planner_messages = [
                msg for msg in result.messages if msg.source == "PlanningAgent"
            ]
            if planner_messages:
                # Find the last substantial message before TERMINATE
                for msg in reversed(planner_messages):
                    if "TERMINATE" not in msg.content and len(msg.content) > 100:
                        final_response = msg.content
                        break

        # Fallback: if still no response, aggregate all meaningful responses
        if not final_response:
            logger.warning(
                "No final aggregated response found from planner. Attempting to aggregate all responses."
            )
            all_responses = []
            for message in result.messages:
                if len(message.content) > 50 and "TERMINATE" not in message.content:
                    all_responses.append(f"**{message.source}**: {message.content}")
            final_response = (
                "\n\n".join(all_responses)
                if all_responses
                else "No meaningful response generated."
            )

        logger.info(
            f"AutoGen task completed successfully. Response length: {len(final_response)}"
        )
        return final_response

    except Exception as e:
        logger.error(f"Error in AutoGen task: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AutoGen task failed: {str(e)}")


async def run_autogen_task_streaming(question: str, event_manager: StreamEventManager) -> AsyncGenerator[str, None]:
    """Run the AutoGen task with streaming events"""
    try:
        logger.info(f"Starting streaming AutoGen task with question: {question[:100]}...")
        
        # Emit starting event
        event = await event_manager.emit_event(
            StreamEventType.STARTED,
            message=f"Starting analysis for: {question[:100]}...",
            data={"question": question, "progress": 0}
        )
        yield f"data: {{\"event\": {event.model_dump_json()}}}\n\n"
        await asyncio.sleep(0.5)
        
        # Emit planner thinking event
        event_manager.increment_step()
        event = await event_manager.emit_event(
            StreamEventType.AGENT_THINKING,
            agent_name="PlanningAgent",
            message="Planning task breakdown and agent coordination...",
            data={"progress": event_manager.get_progress_percentage()}
        )
        yield f"data: {{\"event\": {event.model_dump_json()}}}\n\n"
        await asyncio.sleep(1)

        # Create the task
        task = f"Generate a comprehensive business insights report based on this request: {question}"
        
        # Emit carbon agent event
        event_manager.increment_step()
        event = await event_manager.emit_event(
            StreamEventType.AGENT_THINKING,
            agent_name="CarbonAgent",
            message="Generating synthetic data tables...",
            data={"progress": event_manager.get_progress_percentage()}
        )
        yield f"data: {{\"event\": {event.model_dump_json()}}}\n\n"
        await asyncio.sleep(1)

        # Start the AutoGen team task in background
        result_task = asyncio.create_task(team.run(task=task))
        
        # Simulate progress while waiting for actual result
        simulation_steps = [
            ("CarbonAgent", "Data tables generated successfully"),
            ("DataAnalysisAgent", "Analyzing data and generating insights..."),
            ("DataAnalysisAgent", "Analysis completed, insights generated"),
            ("ReportAgent", "Creating ASCII dashboard report..."),
            ("ReportAgent", "ASCII dashboard generated"),
            ("PlanningAgent", "Finalizing comprehensive report...")
        ]
        
        step_delay = 2.0  # 2 seconds per step
        for i, (agent, message) in enumerate(simulation_steps):
            if not result_task.done():
                event_manager.increment_step()
                event = await event_manager.emit_event(
                    StreamEventType.AGENT_RESPONSE,
                    agent_name=agent,
                    message=message,
                    data={"progress": min(event_manager.get_progress_percentage(), 95)}
                )
                yield f"data: {{\"event\": {event.model_dump_json()}}}\n\n"
                await asyncio.sleep(step_delay)
            else:
                break

        # Wait for the actual result
        result = await result_task
        
        # Process the final response
        final_response = ""
        agent_responses = {}
        
        # Track agent responses for logging
        for message in result.messages:
            agent_name = message.source
            if agent_name not in agent_responses:
                agent_responses[agent_name] = []
            agent_responses[agent_name].append(message.content)
            
            # Log each agent's contribution
            stream_logger.info(f"Agent {agent_name} contributed {len(message.content)} characters")

        # Extract final response (same logic as before)
        for message in result.messages:
            if message.source == "PlanningAgent":
                if any(
                    keyword in message.content
                    for keyword in [
                        "Executive Summary",
                        "Final Aggregated Response",
                        "COMPREHENSIVE FINAL RESPONSE",
                    ]
                ):
                    final_response = message.content
                    break

        if not final_response:
            planner_messages = [
                msg for msg in result.messages if msg.source == "PlanningAgent"
            ]
            if planner_messages:
                for msg in reversed(planner_messages):
                    if "TERMINATE" not in msg.content and len(msg.content) > 100:
                        final_response = msg.content
                        break

        if not final_response:
            all_responses = []
            for message in result.messages:
                if len(message.content) > 50 and "TERMINATE" not in message.content:
                    all_responses.append(f"**{message.source}**: {message.content}")
            final_response = (
                "\n\n".join(all_responses)
                if all_responses
                else "No meaningful response generated."
            )

        # Emit completion event with final response
        event = await event_manager.emit_event(
            StreamEventType.COMPLETED,
            agent_name="PlanningAgent",
            message="Task completed successfully",
            data={
                "progress": 100,
                "final_response": final_response,
                "total_messages": len(result.messages),
                "agent_count": len(agent_responses),
                "response_length": len(final_response)
            }
        )
        yield f"data: {{\"event\": {event.model_dump_json()}}}\n\n"

        logger.info(f"Streaming AutoGen task completed. Response length: {len(final_response)}")
        
    except Exception as e:
        logger.error(f"Error in streaming AutoGen task: {str(e)}")
        stream_logger.error(f"Streaming task failed: {str(e)}")
        
        error_event = await event_manager.emit_event(
            StreamEventType.ERROR,
            message=f"Task failed: {str(e)}",
            data={"error": str(e), "progress": event_manager.get_progress_percentage()}
        )
        yield f"data: {{\"event\": {error_event.model_dump_json()}}}\n\n"


@app.post("/ask", response_model=APIResponse)
async def ask_endpoint(request: QuestionRequest):
    """
    Main endpoint to process questions and return business insights
    """
    try:
        logger.info(f"Received question: {request.question[:100]}...")

        # Run the AutoGen task
        response_content = await run_autogen_task(request.question)

        # Return the response in the expected format
        return APIResponse(
            status="Success",
            message=MessageResponse(role="assistant", content=response_content),
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error in ask endpoint: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"An unexpected error occurred: {str(e)}"
        )


@app.post("/ask-stream")
async def ask_stream_endpoint(request: QuestionRequest):
    """
    Streaming endpoint that provides real-time updates during agent processing
    """
    async def generate_stream():
        event_manager = StreamEventManager()
        
        try:
            stream_logger.info(f"Starting streaming request for: {request.question[:100]}...")
            
            # Create the streaming generator
            async for event_data in run_autogen_task_streaming(request.question, event_manager):
                yield event_data
                
        except Exception as e:
            logger.error(f"Error in streaming endpoint: {str(e)}")
            stream_logger.error(f"Streaming failed: {str(e)}")
            
            # Send error event
            error_event = await event_manager.emit_event(
                StreamEventType.ERROR,
                message=f"Stream failed: {str(e)}",
                data={"error": str(e)}
            )
            yield f"data: {{\"event\": {error_event.model_dump_json()}}}\n\n"

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )


@app.get("/health")
async def health_check():
    """Enhanced health check endpoint with system status. Possible status: Healthy, Warning, Error, Unhealthy"""
    try:
        # Check if agents are initialized
        agents_status = "initialized" if team is not None else "not_initialized"
        
        # Get current timestamp
        current_time = datetime.now().isoformat()
        
        # Check OpenAI client status
        openai_client_status = "connected" if openai_client is not None else "not_connected"
        
        # Test actual OpenAI API connectivity and quota
        openai_api_status = "unknown"
        api_error_message = None
        
        if openai_client is not None:
            try:
                # Make a minimal API call to test connectivity and quota
                response = await openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=1
                )
                openai_api_status = "healthy"
            except Exception as api_error:
                error_str = str(api_error)
                if "429" in error_str or "quota" in error_str.lower():
                    openai_api_status = "quota_exceeded"
                elif "401" in error_str or "invalid" in error_str.lower():
                    openai_api_status = "invalid_key"
                elif "403" in error_str:
                    openai_api_status = "forbidden"
                else:
                    openai_api_status = "error"
                api_error_message = error_str
        
        # Check data directory and files
        data_dir_exists = os.path.exists("src/data")
        data_files_count = 0
        if data_dir_exists:
            try:
                data_files_count = len([f for f in os.listdir("src/data") if f.endswith('.json')])
            except:
                data_files_count = 0
        
        # Check if required environment variables are set
        api_key_configured = bool(openai_api_key and openai_api_key.startswith("sk-"))
        
        # Determine overall status based on all checks
        overall_status = "healthy"
        
        if openai_api_status in ["quota_exceeded", "invalid_key", "forbidden"]:
            overall_status = "warning"
        elif openai_api_status == "error":
            overall_status = "error"
        elif agents_status != "initialized" or openai_client_status != "connected":
            overall_status = "warning"
        
        # Create appropriate message
        if overall_status == "error":
            if openai_api_status == "quota_exceeded":
                message = "OpenAI API quota exceeded. Please check your billing details."
            elif openai_api_status == "invalid_key":
                message = "OpenAI API key is invalid. Please check your API key."
            elif openai_api_status == "forbidden":
                message = "OpenAI API access forbidden. Please check your API key permissions."
        elif overall_status == "warning":
            message = "Some components have issues but system is partially operational."
        else:
            message = "AutoGen Agents and Services are operational."
        
        return {
            "status": overall_status,
            "message": message,
            "timestamp": current_time,
            "components": {
                "agents_status": agents_status,
                "openai_client_status": openai_client_status,
                "openai_api_status": openai_api_status,
                "api_key_configured": api_key_configured,
                "data_directory_exists": data_dir_exists,
                "data_files_count": data_files_count
            },
            "api_error": api_error_message,
            "version": "1.0.0",
            "uptime_check": current_time
        }
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "message": f"AutoGen Business Insights API encountered an error: {str(e)}"
        }


@app.get("/test-stream")
async def test_stream():
    """Test streaming endpoint with mock events"""
    async def generate_test_stream():
        event_manager = StreamEventManager()
        
        test_events = [
            (StreamEventType.STARTED, "System", "Test stream started"),
            (StreamEventType.AGENT_THINKING, "TestAgent", "Processing test request..."),
            (StreamEventType.AGENT_RESPONSE, "TestAgent", "Generated test response"),
            (StreamEventType.COMPLETED, "System", "Test completed successfully")
        ]
        
        for event_type, agent, message in test_events:
            event = await event_manager.emit_event(event_type, agent, message)
            yield f"data: {{\"event\": {event.model_dump_json()}}}\n\n"
            await asyncio.sleep(1)
    
    return StreamingResponse(
        generate_test_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


@app.get("/")
async def root():
    """Root endpoint"""
    return {"message": "AutoGen Business Insights API", "docs": "/docs", "client": "/client"}


@app.get("/client")
async def serve_client():
    """Serve the streaming client HTML"""
    return FileResponse("streaming_client.html", media_type="text/html")


if __name__ == "__main__":
    uvicorn.run(
        "main:app",  # Replace "main" with your actual filename
        host="0.0.0.0",
        port=8000,
        reload=True,
        timeout_keep_alive=300,  # 5 minutes timeout
        timeout_graceful_shutdown=30,
    )
