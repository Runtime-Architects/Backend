"""
Ground truth generator that uses compressed CO2 data for evaluation
Handles UTF-8 encoding for special characters and emojis
"""
import json
import datetime
import os
import re
import subprocess
import glob
from typing import Dict, List, Tuple, Optional

class RealDataGroundTruthGenerator:
    def __init__(self, compressed_data_file: str = None, query_date: Optional[str] = None):
        """Load COMPRESSED carbon intensity data for specific date if provided"""
        self.query_date = query_date
        
        if compressed_data_file is None:
            # If we have a specific date, try to get data for that date
            if query_date:
                compressed_data_file = self.get_or_generate_data_for_date(query_date)
            else:
                # Auto-find compressed data
                compressed_data_file = self.find_compressed_data()
        
        if not os.path.exists(compressed_data_file):
            raise FileNotFoundError(f"Compressed carbon data file not found: {compressed_data_file}. Please run CO2DataCompressor first.")
            
        with open(compressed_data_file, 'r', encoding='utf-8') as f:
            self.carbon_data = json.load(f)
        
        print(f"Loaded COMPRESSED carbon data: {compressed_data_file}")
        if query_date:
            print(f"Using data for specific date: {query_date}")
        
        # Load examples for consistent ground truth generation
        self.examples = self.load_examples()
        
        # Use compressed data points directly
        if 'data' in self.carbon_data and isinstance(self.carbon_data['data'], list):
            self.data_points = self.carbon_data['data']
            print(f"Using {len(self.data_points)} compressed data points")
        else:
            raise ValueError("Invalid compressed data format")
    
    def load_examples(self):
        """Load examples.json for consistent ground truth"""
        try:
            with open('examples.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(" Warning: examples.json not found")
            return {"good_examples": [], "format_requirements": {}}
        except Exception as e:
            print(f" Warning: Error loading examples.json: {e}")
            return {"good_examples": [], "format_requirements": {}}
    
    def extract_date_from_query(self, query: str) -> Optional[str]:
        """Extract date from query text"""
        today = datetime.datetime.now()
        
        # Check for relative date references
        if any(word in query.lower() for word in ['today', 'current', 'now', 'real-time']):
            return today.strftime('%Y-%m-%d')
        elif 'tomorrow' in query.lower():
            return (today + datetime.timedelta(days=1)).strftime('%Y-%m-%d')
        elif 'yesterday' in query.lower():
            return (today - datetime.timedelta(days=1)).strftime('%Y-%m-%d')
        elif 'next week' in query.lower():
            return (today + datetime.timedelta(days=7)).strftime('%Y-%m-%d')
        elif 'last week' in query.lower():
            return (today - datetime.timedelta(days=7)).strftime('%Y-%m-%d')
        
        # Check for explicit dates in various formats
        date_patterns = [
            r'(\d{4}-\d{2}-\d{2})',  # YYYY-MM-DD
            r'(\d{2}/\d{2}/\d{4})',  # MM/DD/YYYY
            r'(\d{2}-\d{2}-\d{4})',  # DD-MM-YYYY
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, query)
            if match:
                date_str = match.group(1)
                try:
                    # Parse and normalize to YYYY-MM-DD
                    if '/' in date_str:
                        date_obj = datetime.datetime.strptime(date_str, '%m/%d/%Y')
                    elif date_str.count('-') == 2 and len(date_str.split('-')[0]) == 2:
                        date_obj = datetime.datetime.strptime(date_str, '%d-%m-%Y')
                    else:
                        date_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d')
                    return date_obj.strftime('%Y-%m-%d')
                except:
                    continue
        
        # Default to today if no date found
        return today.strftime('%Y-%m-%d')
    
    def get_or_generate_data_for_date(self, target_date: str) -> str:
        """Get compressed data for specific date, running scraper if needed"""
        # First check if we already have compressed data for this date
        existing_file = self.find_compressed_data_for_date(target_date)
        if existing_file:
            print(f"Found existing compressed data for {target_date}: {existing_file}")
            return existing_file
        
        # Need to run scraper for this date
        print(f"No compressed data found for {target_date}, running scraper...")
        
        # Run the scraper
        scraper_result = self.run_scraper_for_date(target_date)
        if not scraper_result:
            raise ValueError(f"Failed to get data for date {target_date}")
        
        # Compress the scraped data
        from co2_data_compressor import CO2DataCompressor
        compressor = CO2DataCompressor(scraper_result)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        compressed_file = f"data/co2_intensity_compressed_{target_date}_{timestamp}.json"
        _, compressed_path = compressor.save_compressed(compressed_file)
        
        return compressed_path
    
    def find_compressed_data_for_date(self, target_date: str) -> Optional[str]:
        """Find compressed data file for specific date"""
        possible_patterns = [
            f"data/co2_intensity_compressed_{target_date}_*.json",
            f"data/co2_intensity_compressed_*{target_date}*.json",
            f"./data/co2_intensity_compressed_*{target_date}*.json"
        ]
        
        for pattern in possible_patterns:
            files = glob.glob(pattern)
            if files:
                # Return most recent file for this date
                return max(files, key=os.path.getmtime)
        
        return None
    
    def run_scraper_for_date(self, target_date: str) -> Optional[str]:
        """Run the EirGrid scraper for specific date"""
        try:
            # Use -m to run as module to fix import issues
            cmd = [
                'python', '-m',
                'scraper_tools.run_eirgrid_downloader',
                '--areas', 'co2_intensity',
                '--start', target_date,
                '--end', target_date,
                '--region', 'all',
                '--forecast',
                '--output-dir', './data'
            ]
            
            print(f"Running scraper: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"Scraper error: {result.stderr}")
                return None
            
            # Find the generated file
            pattern = f"data/co2_intensity/co2_intensity_all_{target_date}_{target_date}.json"
            files = glob.glob(pattern)
            if files:
                return files[0]
            
            # Try alternative patterns
            alt_patterns = [
                f"data/co2_intensity_{target_date}*.json",
                f"data/co2_intensity_*{target_date}*.json"
            ]
            for pattern in alt_patterns:
                files = glob.glob(pattern)
                if files:
                    return max(files, key=os.path.getmtime)
            
            return None
            
        except Exception as e:
            print(f"Error running scraper: {e}")
            return None
    
    def find_compressed_data(self) -> str:
        """Find compressed CO2 data file"""
        import glob
        
        # Look for compressed data files
        possible_patterns = [
            "co2_intensity_compressed_*.json",
            "data/co2_intensity_compressed_*.json",
            "./data/co2_intensity_compressed_*.json",
            "*_compressed.json",
            "data/*_compressed.json"
        ]
        
        all_files = []
        for pattern in possible_patterns:
            files = glob.glob(pattern)
            all_files.extend(files)
        
        if all_files:
            # Get the most recent compressed file
            latest_file = max(all_files, key=os.path.getmtime)
            print(f" Found compressed CO2 data: {latest_file}")
            return latest_file
        
        # If no compressed file found, try to create one
        print(" No compressed data found, creating from raw data...")
        try:
            from co2_data_compressor import CO2DataCompressor
            return CO2DataCompressor.prepare_for_evaluation()
        except Exception as e:
            raise FileNotFoundError(
                f"Could not find or create compressed CO2 data. Please ensure:\n"
                f"1. Scraper has been run to generate data\n"
                f"2. Data compression has been performed\n"
                f"Error: {e}"
            )
    
    def find_optimal_periods(self) -> Dict:
        """Analyze compressed CO2 data to find optimal and peak periods"""
        
        if not self.data_points:
            raise ValueError("No compressed data points available for analysis")
        
        # Extract values and times from compressed data
        intensities = []
        for entry in self.data_points:
            try:
                time_str = entry['time']  # Already in HH:MM format from compression
                value = float(entry['value'])
                
                # Parse time
                hour, minute = map(int, time_str.split(':'))
                
                intensities.append({
                    'time': time_str,
                    'intensity': value,
                    'hour': hour,
                    'minute': minute
                })
                
            except Exception as e:
                print(f" Error processing entry {entry}: {e}")
                continue
        
        if not intensities:
            raise ValueError("No valid intensity data could be processed")
        
        print(f" Analyzing {len(intensities)} compressed data points")
        
        # Find minimum and maximum intensity values
        min_entry = min(intensities, key=lambda x: x['intensity'])
        max_entry = max(intensities, key=lambda x: x['intensity'])
        
        print(f" Minimum CO2: {min_entry['intensity']:.0f}g CO2/kWh at {min_entry['time']}")
        print(f" Maximum CO2: {max_entry['intensity']:.0f}g CO2/kWh at {max_entry['time']}")
        
        # Create optimal window around minimum (ensure 3-hour window)
        min_hour = min_entry['hour']
        # Create a broader, more generous window for optimal times
        if min_hour <= 1:  # Very early morning
            optimal_start, optimal_end = 0, 3
        elif min_hour <= 4:  # Early morning  
            optimal_start, optimal_end = min_hour - 1, min_hour + 2
        elif 19 <= min_hour <= 23:  # Evening optimal (common pattern)
            optimal_start, optimal_end = max(19, min_hour - 1), min(23, min_hour + 2)
        else:  # Other times
            optimal_start = max(0, min_hour - 1)
            optimal_end = min(23, min_hour + 2)
            
        optimal_window = {
            'time_range': f"{optimal_start:02d}:00-{optimal_end:02d}:00",
            'min_intensity': int(min_entry['intensity']),
            'max_intensity': int(min_entry['intensity'] + 10),  # Small range around minimum
            'intensity_range': f"{int(min_entry['intensity'])}-{int(min_entry['intensity'] + 10)}g CO2/kWh"
        }
        
        # Create peak window around maximum (ensure 3-hour window)  
        max_hour = max_entry['hour']
        # Create broader peak windows, often in early morning
        if 3 <= max_hour <= 7:  # Early morning peak (common pattern)
            peak_start, peak_end = max(0, max_hour - 1), min(7, max_hour + 2) 
        elif max_hour <= 2:  # Very early morning
            peak_start, peak_end = 0, 3
        else:  # Other peak times
            peak_start = max(0, max_hour - 1)
            peak_end = min(23, max_hour + 2)
            
        peak_window = {
            'time_range': f"{peak_start:02d}:00-{peak_end:02d}:00",
            'intensity_range': f"{int(max_entry['intensity'] - 10)}-{int(max_entry['intensity'])}g CO2/kWh",
            'max_intensity': int(max_entry['intensity'])
        }
        
        # Calculate period averages from compressed data
        morning_entries = [e for e in intensities if 6 <= e['hour'] <= 11]
        morning_avg = int(sum(e['intensity'] for e in morning_entries) / len(morning_entries)) if morning_entries else 250
        
        afternoon_entries = [e for e in intensities if 12 <= e['hour'] <= 17]
        afternoon_avg = int(sum(e['intensity'] for e in afternoon_entries) / len(afternoon_entries)) if afternoon_entries else 230
        
        evening_entries = [e for e in intensities if 18 <= e['hour'] <= 23]
        evening_avg = int(sum(e['intensity'] for e in evening_entries) / len(evening_entries)) if evening_entries else 280
        
        overnight_entries = [e for e in intensities if e['hour'] <= 5 or e['hour'] >= 22]
        overnight_avg = int(sum(e['intensity'] for e in overnight_entries) / len(overnight_entries)) if overnight_entries else 180
        
        # Calculate daily statistics from compressed data
        all_values = [e['intensity'] for e in intensities]
        daily_average = int(sum(all_values) / len(all_values))
        absolute_min = int(min(all_values))
        absolute_max = int(max(all_values))
        
        print(f" Compressed data analysis complete:")
        print(f"   Daily range: {absolute_min}-{absolute_max}g CO2/kWh")
        print(f"   Daily average: {daily_average}g CO2/kWh")
        
        return {
            'optimal': optimal_window,
            'peak': peak_window,
            'morning_avg': morning_avg,
            'afternoon_avg': afternoon_avg,
            'evening_avg': evening_avg,
            'overnight_avg': overnight_avg,
            'current_intensity': afternoon_avg,  # Use afternoon as typical current
            'absolute_min': absolute_min,
            'absolute_max': absolute_max,
            'daily_average': daily_average,
            'data_source': 'compressed_eirgrid_data',
            'data_points': len(intensities),
            'analysis_timestamp': datetime.datetime.now().isoformat()
        }
    
    def create_example_based_reference(self, periods: Dict, test_id: str, test_case: Dict = None) -> str:
        """Create reference output based on examples.json structure with real compressed data"""
        
        # Find matching good example for this test type
        matching_example = None
        if self.examples.get("good_examples"):
            for example in self.examples["good_examples"]:
                if "ev" in test_id.lower() and "ev" in example.get("id", "").lower():
                    matching_example = example
                    break
                elif "data" in test_id.lower() and "data" in example.get("id", "").lower():
                    matching_example = example
                    break
                elif "appliances" in test_id.lower() and "appliances" in example.get("id", "").lower():
                    matching_example = example
                    break
        
        # Get actual data values from compressed data
        optimal_range = periods['optimal']['time_range']
        optimal_intensity_range = f"{periods['optimal']['min_intensity']}-{periods['optimal']['max_intensity']}g CO2/kWh"
        peak_range = periods['peak']['time_range'] 
        peak_intensity_range = periods['peak']['intensity_range']
        daily_avg = periods['daily_average']
        
        # Calculate environmental impact percentage based on actual data
        impact_percentage = int(((periods['absolute_max'] - periods['absolute_min']) / periods['absolute_max']) * 100)
        
        # Get category from test case if provided
        category = test_case.get('category', '') if test_case else ''
        query_text = test_case.get('query', '') if test_case else ''
        
        # Handle different test categories
        if category == 'irrelevant_query' or 'irrelevant' in test_id:
            return """I appreciate your question, but I'm specialized in providing carbon emissions and energy data for Ireland. I can help you with:

â€¢ Optimal times to use appliances based on carbon intensity
â€¢ EV charging recommendations for minimal emissions
â€¢ Real-time CO2 intensity data from EirGrid
â€¢ Historical carbon emission patterns
â€¢ Regional comparisons within Ireland

For weather information, I'd recommend checking a dedicated weather service. Is there anything related to carbon emissions or energy usage I can help you with instead?"""
        
        elif category == 'error_handling' or 'error' in test_id:
            return """I noticed there's an issue with the date format in your request. The date "2025-13-45" appears to be invalid as:

â€¢ Month "13" doesn't exist (valid range: 01-12)
â€¢ Day "45" doesn't exist in any month (valid range: 01-31)

Please provide a valid date in one of these formats:
â€¢ YYYY-MM-DD (e.g., 2025-07-30)
â€¢ DD/MM/YYYY (e.g., 30/07/2025)

I can provide carbon intensity data for any valid date within the available range. Would you like to try again with a corrected date?"""
        
        elif category == 'comparison_query' or 'comparison' in test_id:
            return f"""ğŸ” **Carbon Intensity Comparison: ROI vs Northern Ireland**

**ğŸ“Š Current Data Comparison:**

**ğŸ‡®ğŸ‡ª Republic of Ireland:**
- Current Intensity: {periods['current_intensity']}g CO2/kWh
- Daily Range: {periods['absolute_min']}-{periods['absolute_max']}g CO2/kWh
- Optimal Period: {periods['optimal']['time_range']} ({periods['optimal']['intensity_range']})

**ğŸ´ó §ó ¢ó ®ó ©ó ²ó ¿ Northern Ireland:**
- Current Intensity: {periods['current_intensity'] + 15}g CO2/kWh (typically 10-20g higher)
- Daily Range: {periods['absolute_min'] + 10}-{periods['absolute_max'] + 10}g CO2/kWh
- Optimal Period: {periods['optimal']['time_range']} (similar patterns)

**ğŸ”„ Key Differences:**
â€¢ ROI generally has 10-15g CO2/kWh lower emissions due to higher wind generation
â€¢ Both regions share similar daily patterns with optimal times during {periods['optimal']['time_range']}
â€¢ ROI benefits from interconnection with cleaner European grids

**ğŸ“ˆ Recommendation:** For minimal carbon footprint, use appliances during {periods['optimal']['time_range']} in both regions, with ROI showing slightly better performance."""
        
        elif category == 'analysis_query' or 'statistical' in test_id or 'summary' in test_id:
            last_week_avg = periods['daily_average'] - 10  # Simulate historical average
            return f"""ğŸ“ˆ **Statistical Summary: Ireland Carbon Emissions (Last Week)**

**ğŸ“Š Weekly Statistics:**
- **Average Intensity:** {last_week_avg}g CO2/kWh
- **Minimum Recorded:** {periods['absolute_min'] - 5}g CO2/kWh (typically Sunday 03:00)
- **Maximum Recorded:** {periods['absolute_max'] + 15}g CO2/kWh (typically Thursday 18:30)
- **Daily Variance:** Â±{int((periods['absolute_max'] - periods['absolute_min']) / 2)}g CO2/kWh

**ğŸ“… Daily Breakdown (Last Week):**
- **Monday:** {last_week_avg + 5}g avg, peak: 17:30 ({periods['absolute_max']}g)
- **Tuesday:** {last_week_avg + 8}g avg, peak: 18:00 ({periods['absolute_max'] + 10}g)
- **Wednesday:** {last_week_avg + 3}g avg, peak: 17:45 ({periods['absolute_max'] - 5}g)
- **Thursday:** {last_week_avg + 12}g avg, peak: 18:30 ({periods['absolute_max'] + 15}g)
- **Friday:** {last_week_avg + 7}g avg, peak: 19:00 ({periods['absolute_max'] + 5}g)
- **Saturday:** {last_week_avg - 8}g avg, lowest weekly emissions
- **Sunday:** {last_week_avg - 15}g avg, best day for high-energy activities

**ğŸ” Key Patterns:**
â€¢ Weekday evenings show highest emissions (17:00-19:00)
â€¢ Weekend mornings optimal for appliance usage
â€¢ {impact_percentage}% improvement possible by timing optimization"""
        
        elif matching_example and ("ev" in test_id.lower() or category == 'ev_charging'):
            # EV-specific reference with actual compressed data values
            return f"""ğŸ”‹ **Optimal EV Charging Schedule Based on REAL EirGrid Data:**

ğŸŒ± **Best Charging Window (Real CO2 Data):**
- **{optimal_range}**: Lowest real carbon intensity ({optimal_intensity_range})
- Based on current EirGrid compressed data measurements

âš¡ **EV Charging Strategy (Real Data-Based):**
â€¢ **Immediate charging needed**: If below 20% battery, charge now
â€¢ **Planned charging**: Set timer to start at {optimal_range.split('-')[0]} (real optimal time)
â€¢ **Full daytime charge**: Begin at {optimal_range.split('-')[0]} for complete charge during low emissions
â€¢ **Top-up charging**: Use any time during {optimal_range} window

ğŸ”¥ **Avoid These Real High Emission Times:**
- **{peak_range}**: Peak grid demand ({peak_intensity_range}) from real data

ğŸ“Š **Today's Real CO2 Intensity Range:**
- Minimum: {periods['absolute_min']}g CO2/kWh
- Maximum: {periods['absolute_max']}g CO2/kWh
- Daily Average: {daily_avg}g CO2/kWh

ğŸŒ **Environmental Benefit**: Charging during optimal hours reduces your EV's carbon footprint by {impact_percentage}% compared to peak times (calculated from today's real EirGrid data)!"""
        
        elif matching_example and "data" in test_id.lower():
            # Data request reference
            return f"""ğŸ“Š **REAL CO2 Intensity Data - Ireland (Based on EirGrid Measurements)**

ğŸ• **24-Hour Real Data Breakdown:**

**ğŸŒ™ Overnight (Real EirGrid Data):**
- 00:00-06:00: {periods['overnight_avg']}g CO2/kWh {'ğŸŒ±' if periods['overnight_avg'] < periods['daily_average'] else 'âš ï¸'} (real measurements)
- Optimal window: {optimal_range} ({optimal_intensity_range}) - confirmed lowest real emissions

**ğŸŒ… Morning (Real Grid Data):**
- 06:00-12:00: {periods['morning_avg']}g CO2/kWh {'ğŸŒ±' if periods['morning_avg'] < periods['daily_average'] else 'âš ï¸'} (real EirGrid measurements)

**â˜€ï¸ Afternoon (Live Data):**
- 12:00-18:00: {periods['afternoon_avg']}g CO2/kWh {'ğŸŒ±' if periods['afternoon_avg'] < periods['daily_average'] else 'âš ï¸'} (current EirGrid readings)

**ğŸŒ† Evening (Real Peak Data):**
- 18:00-24:00: {periods['evening_avg']}g CO2/kWh {'âš ï¸' if periods['evening_avg'] > periods['daily_average'] else 'ğŸŒ±'} (real measurements)

**ğŸ“ˆ Real Daily Summary (EirGrid Data):**
- **Minimum**: {periods['absolute_min']}g CO2/kWh (cleanest real grid measurement)
- **Maximum**: {periods['absolute_max']}g CO2/kWh (highest real emission reading)
- **Daily Average**: {daily_avg}g CO2/kWh (calculated from real data)
- **Data Source**: Compressed EirGrid CO2 intensity measurements"""
        
        else:
            # Default appliances reference
            return f"""ğŸ  **Best Times to Use Appliances in Ireland Today (Based on REAL EirGrid Data):**

ğŸŒ± **Optimal Period (Lowest Real CO2):**
- **{optimal_range}**: {optimal_intensity_range} (REAL EirGrid data)
- Perfect for washing machine, dishwasher, and EV charging

âš¡ **Specific Appliance Recommendations (Real Data-Based):**
â€¢ **Washing Machine**: Start cycle at {optimal_range.split('-')[0]}
â€¢ **Dishwasher**: Schedule for {optimal_range}
â€¢ **Electric Vehicle Charging**: Begin charging during real low-emission window
â€¢ **Tumble Dryer**: Use during optimal period

ğŸ”¥ **Avoid High Real Emission Times:**
- **{peak_range}**: {peak_intensity_range} (real peak demand data)

ğŸ“Š **Today's REAL EirGrid CO2 Data:**
- Minimum: {periods['absolute_min']}g CO2/kWh (real measurement)
- Maximum: {periods['absolute_max']}g CO2/kWh (real measurement)  
- Daily Average: {daily_avg}g CO2/kWh (real average)

ğŸŒ **Environmental Impact**: Using appliances during optimal times reduces your carbon footprint by up to {impact_percentage}% compared to peak times (calculated from real data)!"""
    
    def create_realistic_scoring_criteria(self, periods: Dict, test_id: str, test_case: Dict = None) -> Dict:
        """Create test-specific scoring criteria based on test type"""
        
        format_reqs = self.examples.get("format_requirements", {})
        
        # Base scoring weights (same for all tests)
        scoring_weights = {
            "accuracy_vs_real_data": 0.30,
            "completeness": 0.25,
            "clarity": 0.20,
            "actionability": 0.15,
            "format": 0.10
        }
        
        # Get category from test case if provided
        category = test_case.get('category', '') if test_case else ''
        
        # Test-specific criteria based on category or ID
        if category == 'irrelevant_query' or 'irrelevant' in test_id:
            # For irrelevant queries, we don't expect carbon-specific content
            return {
                "content_requirements": {
                    "must_have": [
                        "appropriate response indicating query is outside domain",
                        "polite redirection or explanation"
                    ],
                    "should_have": [
                        "explanation that the system focuses on carbon emissions",
                        "suggestion to ask carbon-related questions"
                    ],
                    "format_requirements": [
                        "Clear communication",
                        "Professional tone"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "attempts to answer weather/non-carbon query: -0.30",
                    "uses get_emission_analysis for non-carbon query: -0.40",
                    "no clear indication of domain limits: -0.10"
                ]
            }
        elif category == 'error_handling' or 'error' in test_id:
            # For error handling tests
            return {
                "content_requirements": {
                    "must_have": [
                        "error detection and appropriate error message",
                        "clear explanation of the issue"
                    ],
                    "should_have": [
                        "helpful suggestion for correction",
                        "professional error handling"
                    ],
                    "format_requirements": [
                        "Clear error message",
                        "User-friendly explanation"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "no error detection: -0.40",
                    "crashes or throws exception: -0.50",
                    "provides data for invalid date: -0.30"
                ]
            }
        elif category == 'comparison_query' or 'comparison' in test_id:
            # For comparison queries
            return {
                "content_requirements": {
                    "must_have": [
                        "data for both regions mentioned (ROI and Northern Ireland)",
                        f"carbon intensity values within {periods['absolute_min']}-{periods['absolute_max']}g CO2/kWh range",
                        "clear comparison between regions"
                    ],
                    "should_have": [
                        "specific time periods for comparison",
                        "explanation of differences",
                        "data source mentioned"
                    ],
                    "format_requirements": [
                        "Side-by-side comparison or clear distinction",
                        "CO2 values in g CO2/kWh format",
                        "Regional labels clearly shown"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "no comparison provided: -0.25",
                    "missing data for one region: -0.20",
                    "completely unrealistic CO2 values (e.g., negative numbers, values over 1000g): -0.20"
                ]
            }
        elif category == 'analysis_query' or 'statistical' in test_id or 'summary' in test_id:
            # For statistical/analysis queries
            return {
                "content_requirements": {
                    "must_have": [
                        "statistical summary with min/max/average values",
                        f"carbon values within realistic range ({periods['absolute_min']}-{periods['absolute_max']}g CO2/kWh)",
                        "time period clearly specified (last week)"
                    ],
                    "should_have": [
                        "trend analysis or patterns",
                        "peak and off-peak identification",
                        "daily breakdowns or aggregations"
                    ],
                    "format_requirements": [
                        "Structured statistical presentation",
                        "Clear numerical values",
                        "Time period labels"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "no statistical values provided: -0.25",
                    "wrong time period (not last week): -0.20",
                    "missing key statistics (min/max/avg): -0.15",
                    "completely unrealistic CO2 values (e.g., negative numbers, values over 1000g): -0.20"
                ]
            }
        elif category == 'ev_charging' or "ev" in test_id or "electric" in test_id:
            return {
                "content_requirements": {
                    "must_have": [
                        f"specific optimal charging time window mentioned (broader 3-hour window like {periods['optimal']['time_range']})",
                        "real carbon intensity values from actual EirGrid data (no specific range required)",
                        "EV charging specific advice with multiple strategies",
                        "comparison between optimal and peak times with broader windows", 
                        "clear time recommendations in HH:MM-HH:MM format (not single hours)"
                    ],
                    "should_have": [
                        "environmental impact statement with percentage",
                        "battery charging strategies (immediate vs planned)",
                        "daily CO2 intensity overview",
                        "actionable EV charging advice",
                        "mention of real/actual/live data source"
                    ],
                    "format_requirements": [
                        "Time ranges in HH:MM-HH:MM format",
                        "CO2 values in g CO2/kWh format",
                        "EV-specific charging recommendations",
                        "Clear structure with sections"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "no specific times mentioned: -0.15",
                    "no EV charging advice: -0.15",
                    "narrow time windows (single hour instead of 3-hour window): -0.12",
                    "no real carbon intensity values provided: -0.20",
                    "response under 300 characters: -0.10",
                    "wrong time format (not HH:MM-HH:MM): -0.05",
                    "no comparison between optimal/peak times: -0.10",
                    "completely unrealistic CO2 values (e.g., negative numbers, values over 1000g): -0.20",
                    "no mention of real/actual/live data: -0.10",
                    "missing EV charging strategies (immediate, planned, full, top-up): -0.08"
                ]
            }
        elif "data_request" in test_id or "24 hours" in test_id:
            return {
                "content_requirements": {
                    "must_have": [
                        "24-hour breakdown or comprehensive data overview",
                        f"real carbon intensity values (must be within {periods['absolute_min']}-{periods['absolute_max']}g CO2/kWh range)",
                        "time periods with CO2 values",
                        "daily statistics (min/max/average)",
                        "data source mentioned"
                    ],
                    "should_have": [
                        "period-based breakdown (morning/afternoon/evening/overnight)",
                        "visual indicators or emojis for clarity",
                        "trend information",
                        "optimal and peak windows highlighted"
                    ],
                    "format_requirements": [
                        "Time ranges in HH:MM-HH:MM format",
                        "CO2 values in g CO2/kWh format",
                        "Structured data presentation",
                        "Clear period labels"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "no time periods mentioned: -0.15",
                    "no CO2 intensity values: -0.20", 
                    "completely unrealistic CO2 values (e.g., negative numbers, values over 1000g): -0.20",
                    "response under 300 characters: -0.10",
                    "no daily statistics (min/max/avg): -0.10",
                    "no data source mentioned: -0.05"
                ]
            }
        else:
            # Default (appliances)
            return {
                "content_requirements": {
                    "must_have": [
                        f"specific optimal time period mentioned (broader 3-hour window like {periods['optimal']['time_range']})",
                        "real carbon intensity values from actual EirGrid data (no specific range required)",
                        "at least 3 specific appliances mentioned",
                        "comparison between optimal and peak times with broader windows",
                        "clear time recommendations in HH:MM-HH:MM format (not single hours)"
                    ],
                    "should_have": [
                        "environmental impact statement with percentage",
                        "clear visual structure",
                        "daily overview with real min/max/average values",
                        "actionable scheduling advice",
                        "Ireland context mentioned"
                    ],
                    "format_requirements": [
                        "Time ranges in HH:MM-HH:MM format",
                        "CO2 values in g CO2/kWh format",
                        "At least 3 appliance recommendations",
                        "Clear structure with sections"
                    ]
                },
                "scoring_weights": scoring_weights,
                "penalty_conditions": [
                    "no specific times mentioned: -0.15",
                    "no appliances mentioned: -0.15",
                    "narrow time windows (single hour instead of 3-hour window): -0.12", 
                    "no real carbon intensity values provided: -0.20",
                    "response under 300 characters: -0.10",
                    "wrong time format (not HH:MM-HH:MM): -0.05",
                    "no comparison between optimal/peak times: -0.10",
                    "completely unrealistic CO2 values (e.g., negative numbers, values over 1000g): -0.20",
                    "no mention of real/actual/live data: -0.10"
                ]
            }
    
    def generate_dynamic_test_cases(self, test_queries: Optional[List[Dict]] = None) -> List[Dict]:
        """Generate test cases with dynamic ground truth based on compressed CO2 data"""
        periods = self.find_optimal_periods()
        
        # Get region info from compressed data
        region = self.carbon_data.get('region', 'Ireland').replace('_', ' ')
        if region.lower() == 'all':
            region = 'Ireland'
        elif region.lower() == 'roi':
            region = 'Republic of Ireland'
        elif region.lower() == 'ni':
            region = 'Northern Ireland'
        
        print(f" Generating ground truth for {region} using compressed data")
        print(f" Data range: {periods['absolute_min']}-{periods['absolute_max']}g CO2/kWh")
        print(f" Data points: {periods['data_points']} compressed entries")
        
        # Generate test cases with examples-based ground truth
        if test_queries:
            # Use provided test queries with date extraction
            test_cases = []
            for test_query in test_queries:
                query_text = test_query.get('query', '')
                query_date = self.extract_date_from_query(query_text)
                
                # If date differs from our loaded data date, we may need to reload
                if query_date != self.query_date:
                    print(f"Warning: Query date {query_date} differs from loaded data date {self.query_date}")
                
                test_case = {
                    "id": test_query.get('id', 'custom_test'),
                    "query": query_text,
                    "query_date": query_date,
                    "expected_functions": test_query.get('expected_functions', ["get_emission_analysis"]),
                    "expected_behavior": test_query.get('expected_behavior', ["correct_function_call", "high_quality_response"]),
                    "expected_output_keywords": test_query.get('expected_output_keywords', []),
                    "category": test_query.get('category', 'custom'),
                    "priority": test_query.get('priority', 'medium'),
                    "timeout_seconds": test_query.get('timeout_seconds', 60),
                    "domain_context": test_query.get('domain_context', f"Carbon emissions optimization using compressed EirGrid data for {region}."),
                    "available_functions": test_query.get('available_functions', ["get_emission_analysis"]),
                    "ground_truth": {
                        "reference_output": self.create_example_based_reference(periods, test_query.get('id', ''), test_query),
                        "scoring_criteria": self.create_realistic_scoring_criteria(periods, test_query.get('id', ''), test_query)
                    }
                }
                test_cases.append(test_case)
        else:
            # Default test cases including error scenarios
            test_cases = [
                {
                    "id": "carbon_001_real_appliances",
                    "query": "What is the best time to use my appliances today in Ireland?",
                    "query_date": datetime.datetime.now().strftime('%Y-%m-%d'),
                "expected_functions": ["get_emission_analysis"],
                "expected_behavior": ["correct_function_call", "high_quality_response", "user_friendly"],
                "expected_output_keywords": ["time", "appliances", "Ireland", "carbon", "intensity"],
                "category": "basic_query",
                "priority": "high",
                "timeout_seconds": 60,
                "domain_context": f"Carbon emissions optimization for appliance usage in {region} using compressed EirGrid data.",
                "available_functions": ["get_emission_analysis"],
                "ground_truth": {
                    "reference_output": self.create_example_based_reference(periods, "carbon_001_real_appliances", {"category": "basic_query"}),
                    "scoring_criteria": self.create_realistic_scoring_criteria(periods, "carbon_001_real_appliances", {"category": "basic_query"})
                }
            },
            {
                "id": "carbon_002_real_ev_charging", 
                "query": "When should I charge my electric vehicle for minimal carbon footprint using current data?",
                "query_date": datetime.datetime.now().strftime('%Y-%m-%d'),
                "expected_functions": ["get_emission_analysis"],
                "expected_behavior": ["correct_function_call", "high_quality_response", "domain_expertise"],
                "expected_output_keywords": ["charge", "carbon", "footprint", "time", "electric", "current", "data"],
                "category": "ev_charging",
                "priority": "high",
                "timeout_seconds": 60,
                "domain_context": f"EV charging optimization based on compressed EirGrid CO2 intensity data for {region}.",
                "available_functions": ["get_emission_analysis"],
                "ground_truth": {
                    "reference_output": self.create_example_based_reference(periods, "carbon_002_real_ev_charging", {"category": "ev_charging"}),
                    "scoring_criteria": self.create_realistic_scoring_criteria(periods, "carbon_002_real_ev_charging", {"category": "ev_charging"})
                }
            },
            {
                "id": "carbon_003_real_data_request",
                "query": f"Show me real CO2 intensity data for the next 24 hours in {region}",
                "query_date": datetime.datetime.now().strftime('%Y-%m-%d'),
                "expected_functions": ["get_emission_analysis"],
                "expected_behavior": ["correct_function_call", "high_quality_response"],
                "expected_output_keywords": ["co2", "intensity", "hours", region.lower(), "data", "real"],
                "category": "data_request", 
                "priority": "medium",
                "timeout_seconds": 90,
                "domain_context": f"Real carbon intensity data retrieval from compressed EirGrid data for {region}.",
                "available_functions": ["get_emission_analysis"],
                "ground_truth": {
                    "reference_output": self.create_example_based_reference(periods, "carbon_003_real_data_request", {"category": "data_request"}),
                    "scoring_criteria": self.create_realistic_scoring_criteria(periods, "carbon_003_real_data_request", {"category": "data_request"})
                }
            },
            # ERROR SCENARIO TEST CASES - Only the two requested
            {
                "id": "carbon_004_invalid_date_format",
                "query": "What's the best time for appliances on 2025-13-45?",
                "query_date": "2025-13-45",  # Invalid date
                "expected_functions": [],  # Should not call function with invalid date
                "expected_behavior": ["error_handling", "user_friendly_error"],
                "expected_output_keywords": ["invalid", "date", "format", "error"],
                "category": "error_handling",
                "priority": "high",
                "timeout_seconds": 30,
                "domain_context": "Error handling for invalid date formats in carbon emissions queries.",
                "available_functions": ["get_emission_analysis"],
                "ground_truth": {
                    "reference_output": self.create_example_based_reference(periods, "carbon_004_invalid_date_format", {"category": "error_handling"}),
                    "scoring_criteria": self.create_realistic_scoring_criteria(periods, "carbon_004_invalid_date_format", {"category": "error_handling"})
                }
            },
            {
                "id": "carbon_006_impossible_date",
                "query": "Show me CO2 data for February 30th, 2025",
                "query_date": "2025-02-30",  # February 30th doesn't exist
                "expected_functions": [],
                "expected_behavior": ["error_handling", "date_validation"],
                "expected_output_keywords": ["invalid", "date", "february", "30"],
                "category": "error_handling",
                "priority": "medium",
                "timeout_seconds": 30,
                "domain_context": "Error handling for impossible dates in carbon emissions queries.",
                "available_functions": ["get_emission_analysis"],
                "ground_truth": {
                    "reference_output": self.create_example_based_reference(periods, "carbon_006_impossible_date", {"category": "error_handling"}),
                    "scoring_criteria": self.create_realistic_scoring_criteria(periods, "carbon_006_impossible_date", {"category": "error_handling"})
                }
            }
        ]
        
        return test_cases
    
    def save_dynamic_test_cases(self, output_file: str = "compressed_data_test_cases.json"):
        """Save test cases generated from compressed CO2 data"""
        test_cases = self.generate_dynamic_test_cases()
        
        # Get the query date from the test cases (they should all have the same date)
        query_date = test_cases[0]['query_date'] if test_cases else datetime.datetime.now().strftime('%Y-%m-%d')
        
        # Create the full test cases structure
        test_cases_data = {
            "metadata": {
                "evaluation_framework": "compressed_data_consistency",
                "created_date": datetime.datetime.now().isoformat(),
                "co2_data_source": "compressed_eirgrid_data",
                "co2_data_file": getattr(self, 'compressed_data_file', 'compressed_data.json'),
                "co2_data_date": query_date,
                "co2_data_region": self.carbon_data.get('region', 'all'),
                "compressed_data_points": len(self.data_points),
                "compression_interval": self.carbon_data.get('interval_minutes', 30),
                "data_requirements": [
                    "Uses compressed EirGrid data for consistency",
                    "Ground truth matches compressed data values",
                    "Evaluation uses same compressed data source"
                ]
            },
            "evaluation_guidelines": {
                "scoring_philosophy": "Compare agent outputs against reference outputs based on COMPRESSED EirGrid data",
                "consistency_requirements": "Agent and evaluator must use same compressed data source",
                "penalty_system": "Balanced penalties for missing requirements",
                "ground_truth_priority": "Reference outputs based on compressed CO2 measurements take precedence"
            },
            "compressed_co2_analysis": self.find_optimal_periods(),
            "test_cases": test_cases
        }
        
        # Ensure output directory exists
        output_dir = os.path.dirname(output_file)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(test_cases_data, f, indent=2, ensure_ascii=False)
        
        print(f" Compressed data test cases saved to {output_file}")
        print(f" Generated {len(test_cases)} test cases with ground truth from compressed data")
        print(f" Using {len(self.data_points)} compressed data points")
        
        return output_file
    
    def generate_date_specific_test_cases(self, queries_with_dates: List[Dict]) -> List[Dict]:
        """
        Generate test cases for queries that have specific dates
        This ensures we use the correct date's data for ground truth
        """
        all_test_cases = []
        
        # Group queries by date to minimize scraper runs
        queries_by_date = {}
        for query_info in queries_with_dates:
            query_text = query_info.get('query', '')
            query_date = self.extract_date_from_query(query_text)
            
            if query_date not in queries_by_date:
                queries_by_date[query_date] = []
            queries_by_date[query_date].append(query_info)
        
        # Process each date group
        for query_date, queries in queries_by_date.items():
            try:
                # Get or generate data for this specific date
                compressed_file = self.get_or_generate_data_for_date(query_date)
                
                # Create a new generator instance with this date's data
                date_generator = RealDataGroundTruthGenerator(compressed_file, query_date)
                
                # Generate test cases for this date's queries
                test_cases = date_generator.generate_dynamic_test_cases(queries)
                all_test_cases.extend(test_cases)
                
            except Exception as e:
                print(f"Warning: Could not generate ground truth for date {query_date}: {e}")
                # Fall back to current date data
                test_cases = self.generate_dynamic_test_cases(queries)
                all_test_cases.extend(test_cases)
        
        return all_test_cases
    
    @classmethod
    def generate_from_config_file(cls, config_file: str) -> str:
        """
        Generate test cases with ground truth from a configuration file
        Returns the path to the generated test cases file
        """
        try:
            print(f"Loading test configuration from: {config_file}")
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            test_cases = config.get('test_cases', [])
            evaluation_settings = config.get('evaluation_settings', {})
            
            print(f"Found {len(test_cases)} test cases to process")
            
            # Create generator
            generator = cls()
            
            # Generate test cases with ground truth
            enhanced_test_cases = generator.generate_dynamic_test_cases(test_cases)
            
            # Create output structure
            output_data = {
                "metadata": {
                    "evaluation_framework": "enhanced_multi_instance_with_ground_truth",
                    "created_date": datetime.datetime.now().isoformat(),
                    "source_config": config_file,
                    "total_test_cases": len(enhanced_test_cases),
                    "evaluation_settings": evaluation_settings
                },
                "test_cases": enhanced_test_cases
            }
            
            # Save to output file
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"test_configs/generated_test_cases_with_ground_truth_{timestamp}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            print(f"Generated test cases with ground truth: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"Error generating test cases from config: {e}")
            raise
    
    @staticmethod
    def generate_for_evaluation(compressed_data_file: str = None) -> str:
        """
        Generate test cases for evaluation using compressed CO2 data
        Returns the path to the generated test cases file
        """
        try:
            print("Generating ground truth from COMPRESSED EirGrid CO2 data...")
            
            # Create generator with compressed data
            generator = RealDataGroundTruthGenerator(compressed_data_file)
            
            # Generate and save test cases from compressed data
            output_file = "test_configs/compressed_data_test_cases.json"
            generator.save_dynamic_test_cases(output_file)
            
            print(f" Compressed data test cases ready for evaluation: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"Error generating ground truth from compressed data: {e}")
            print(f"Ensure CO2 data has been compressed first")
            raise

# Alias for backwards compatibility
GroundTruthGenerator = RealDataGroundTruthGenerator

# Usage
if __name__ == "__main__":
    try:
        print("Generating Ground Truth from COMPRESSED EirGrid Data")
        print("=" * 70)
        
        # Generate test cases from compressed data
        generator = RealDataGroundTruthGenerator()
        
        # Generate and save test cases
        output_file = generator.save_dynamic_test_cases("compressed_data_test_cases.json")
        
        print(f"\nCompressed data ground truth completed!")
        print(f"Test cases saved to: {output_file}")
        print(f"All ground truth based on compressed data")
        
    except Exception as e:
        print(f"Error: {e}")
        print(f"Ensure CO2 data has been compressed first!")